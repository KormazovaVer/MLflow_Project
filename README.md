# Докеризированный MLflow/FastAPI сервис для классификации ирисов

Этот проект демонстрирует создание и развертывание MLflow/FastAPI сервиса для классификации ирисов
с использованием scikit-learn и Docker.

MLflow является мощным инструментом для организации ML-проектов. Он позволяет отслеживать параметры,
метрики и артефакты экспериментов, что обеспечивает воспроизводимость результатов и упрощает управление
моделями. Это особенно полезно для сравнения и выбора оптимальной конфигурации даже в простом проекте.

Кроме того, проект включает базовую интеграцию с CI/CD. Этот подход автоматизирует тестирование, 
сборку и развертывание ML-проектов, что способствует быстрому обнаружению ошибок, улучшению
качества кода и ускорению процесса поставки новых версий модели. Все это упаковывается в Docker-контейнеры,
что облегчает развертывание и масштабирование.

Таким образом, этот проект предоставляет ценный опыт использования современных инструментов и практик
для создания и поддержки эффективных ML-сервисов.

## Описание

Проект состоит из следующих частей:

*   **`app/app.py`**: Содержит код для обучения, сохранения модели классификации ирисов (scikit-learn),
                      FastAPI приложение для обработки запросов и предсказания классов ирисов.
*   **`app/Dockerfile`**: Файл для сборки Docker образа для FastAPI.
*   **`docker-compose.yml`**: Файл для управления контейнерами MLflow и FastAPI.
*   **`Dockerfile`**: Файл для сборки Docker образа для MLflow.
*   **`mlruns/`**: это директория, в которой MLflow хранит метаданные, артефакты и логи, связанные с 
                   запусками экспериментов машинного обучения.
*   **`mlartifacts/`**: служит для сохранения файлов (моделей, данных, графиков) вместе с результатами
                        экспериментов ML, обеспечивая их воспроизводимость и отслеживаемость.
*   **`.github/workflows/`**: Содержит реализацию workflow для GitHub Actions CI/CD.
*   **`README.md`**: Этот файл.
*   **`git.ignore`**: Файл с исключениями для Git.
*   **`iris_test.csv`**: Файл для тестирования модели через FastAPI.

## Предварительные требования

*   Docker и Docker Compose установлены.
*   Python 3.8+
*   Аккаунт на GitHub (для CI/CD с GitHub Actions).

## Инструкция по развертыванию

1.  **Клонируйте репозиторий:**

    ```bash
    git clone https://github.com/KormazovaVer/MLflow_Project
    cd MLflow_Project
    ```

2.  **Соберите и запустите Docker контейнеры:**

    ```bash
    docker-compose up --build
    ```
    Это создаст и запустит два контейнера:
    * FastAPI сервис на порту 8000
    * MLflow tracking server на порту 5000

3. **Доступ к сервисам**
   *  API FastAPI: `http://localhost:8000/docs` (для документации Swagger UI)
   *  MLflow UI: `http://localhost:5000`

## Обучение модели

Модель можно обучить, запустив скрипт в директории `app/`:

```bash
    python app/app.py 
```
Это обучит модель, сохранит ее в MLflow.

## Использование API

Отправьте POST запрос к API для классификации ириса:

```bash
    curl -X POST -F "file=@iris_test.csv" http://localhost:8000/predict
```

## CI/CD (GitHub Actions)

Проект включает реализацию workflow для GitHub Actions в .github/workflows/.
Он выполняет следующие шаги:

1. Собирает Docker образ.
2. Тестирует API (пример: pytest api/test_api.p). Тестирование не реализовано.
3. Публикует Docker образ в Docker Hub.

Чтобы настроить CI/CD:

1. Создайте репозиторий на GitHub.
2. Загрузите код в репозиторий.
3. Включите GitHub Actions для вашего репозитория.
4. Настройте секреты GitHub Actions (имя пользователя и пароль Docker Hub) для публикации образа.

## Заключение

### Почему использование простого ML-проекта было оптимальным решением

### Практические преимущества простой модели в контексте MLflow и CI/CD

Для освоения MLflow и внедрения CI/CD-практик я сознательно выбрала классификацию
Iris как базовый проект машинного обучения. Это решение было продиктовано рядом
важных практических соображений:

### Технические преимущества при работе с Docker

1. Оптимизация ресурсов: объёмные ML-проекты требуют значительных вычислительных мощностей
и дискового пространства при локальном развёртывании в Docker-контейнерах. 
Это критически важный фактор, поскольку сложные модели:
   1. Быстро заполняют доступное пространство на диске.
   2. Существенно увеличивают время сборки и развёртывания образов.
   3. Усложняют процесс отладки при возникновении проблем.
2. Тестирование контейнеризации: простая модель позволяет быстро проверить корректность
контейнеризации приложения перед выпуском в облачную среду или на сервер, что является
необходимым этапом разработки.

### Образовательные преимущества

1. Фокус на инфраструктуре: используя простую модель, я смогла сконцентрироваться на освоении
инфраструктурных аспектов MLflow и CI/CD, не отвлекаясь на сложности модели.
2. Ускоренное получение обратной связи: быстрые итерации позволили экспериментировать с
различными подходами к настройке потоков CI/CD и быстро видеть результаты.

### Долгосрочная ценность полученного опыта

Опыт, полученный при работе с простой моделью, закладывает прочный фундамент для будущих проектов:
1. Масштабируемость подхода: отработанные практики легко адаптируются к более сложным
моделям и производственным задачам.
2. Стандартизация процессов: созданные шаблоны CI/CD и конвейеры MLflow можно использовать как
базовую инфраструктуру для любых ML-проектов.
3. Снижение технического долга: правильно выстроенные процессы с самого начала предотвращают
накопление проблем при масштабировании проекта.

### Практический опыт

В процессе работы я убедилась, что даже при использовании простых моделей современные практики
MLOps значительно повышают качество разработки:
1. Воспроизводимость результатов: MLflow позволил отслеживать все эксперименты и их параметры.
2. Автоматизация развёртывания: CI/CD упростил процесс тестирования и доставки модели.
3. Документирование процесса: автоматическое ведение логов и метрик обеспечивает прозрачность разработки.

Таким образом, использование простой модели позволило эффективно освоить MLflow и CI/CD, создать оптимальный 
рабочий процесс и получить ценные навыки, которые несомненно пригодятся при работе с более сложными и ресурсоёмкими
ML-проектами в будущем.   
Спасибо за интересный и полезный курс!
